{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Tokenization\n",
    "Usage examples for the Quadtree image tokenizer and the vanilla ViT tokenizer.\n",
    "\n",
    "The tokenizers prepare input images to be used as input for a standard Transformer model: \\\n",
    "they pass the patch pixels through an encoding layer, add sinusoidal position embeddings \\\n",
    "based on patch locations, and prepend the cls_token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T18:33:26.601252Z",
     "start_time": "2023-09-08T18:33:26.588350Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T18:33:27.254602Z",
     "start_time": "2023-09-08T18:33:26.602748Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from mixed_res.patch_scorers.random_patch_scorer import RandomPatchScorer\n",
    "from mixed_res.quadtree_impl.quadtree_z_curve import ZCurveQuadtreeRunner\n",
    "from mixed_res.tokenization.patch_embed import FlatPatchEmbed, PatchEmbed\n",
    "from mixed_res.tokenization.tokenizers import QuadtreeTokenizer, VanillaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T18:33:27.283851Z",
     "start_time": "2023-09-08T18:33:27.255285Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "image_size = 256\n",
    "channels = 3\n",
    "min_patch_size = 16\n",
    "max_patch_size = 64\n",
    "quadtree_num_patches = 100\n",
    "batch_size = 5\n",
    "embed_dim = 384\n",
    "\n",
    "images = torch.randn(batch_size, channels, image_size, image_size, device=device)\n",
    "cls_token = nn.Parameter(torch.randn(embed_dim)).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize images with a Quadtree tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T18:33:27.609598Z",
     "start_time": "2023-09-08T18:33:27.281975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 101, 384])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These will probably be initialized inside your ViT's __init__ method\n",
    "patch_embed = FlatPatchEmbed(img_size=image_size, patch_size=min_patch_size, embed_dim=embed_dim).to(device)\n",
    "quadtree_runner = ZCurveQuadtreeRunner(quadtree_num_patches, min_patch_size, max_patch_size)\n",
    "patch_scorer = RandomPatchScorer()\n",
    "quadtree_tokenizer = QuadtreeTokenizer(patch_embed, cls_token, quadtree_runner, patch_scorer)\n",
    "\n",
    "# put this in your forward method\n",
    "token_embeds = quadtree_tokenizer.tokenize(images)\n",
    "token_embeds.shape  # [batch_size, 1 + num_patches, embed_dim]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize images with a vanilla ViT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T18:33:27.625098Z",
     "start_time": "2023-09-08T18:33:27.609411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 257, 384])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These will probably be initialized inside your ViT's __init__ method\n",
    "patch_embed = PatchEmbed(img_size=image_size, patch_size=min_patch_size, embed_dim=embed_dim).to(device)\n",
    "vanilla_tokenizer = VanillaTokenizer(patch_embed, cls_token)\n",
    "\n",
    "# put this in your forward method\n",
    "token_embeds = vanilla_tokenizer.tokenize(images)\n",
    "token_embeds.shape  # [batch_size, 1 + (image_size / patch_size)**2, embed_dim]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlskel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
